{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccedd4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da871a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5913227083641d49724418888ddcecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a9ec7e1e2b4a09a70c8bc5358e01b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f600ec97da4008a9b35fb51dfcf8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6fb47dbdc44b3ba6d29d81da540816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b08ba010c1e4f49912af01f59f86abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338a5b3501cd4880bd8c2efbed136075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b83a1af61d457b8cc5fe3819387b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d20d5034274f4baed42cb8155af8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d180599f16b43609294bb1c278b90d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4913390dc6ee4512ac08d58fb652d390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4889a8baa414503a3685b5238255cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a702dfd08051436ab3995f7ea4324b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f53613ee2864b39b2d4eb161f4780b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c078e447b4467d9bd209b4bb0f02b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load SST-2 (a binary sentiment task)\n",
    "raw_ds = load_dataset(\"glue\", \"sst2\")  \n",
    "\n",
    "# 2. Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenized_ds = raw_ds.map(preprocess, batched=True)\n",
    "tokenized_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19869d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5add8b2c4d494657a09b492738f86885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Wrap a pretrained BERT for classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# LoRA config: low-rank adapters on Q/K/V projections\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\",\"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)  # LoRA injects adapters :contentReference[oaicite:2]{index=2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a372e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.5548\n",
      "Epoch 1 loss: 0.6330\n",
      "Epoch 1 loss: 0.6144\n",
      "Epoch 1 loss: 0.5789\n",
      "Epoch 1 loss: 0.5505\n",
      "Epoch 1 loss: 0.5664\n",
      "Epoch 1 loss: 0.6254\n",
      "Epoch 1 loss: 0.5369\n",
      "Epoch 1 loss: 0.5965\n",
      "Epoch 1 loss: 0.5712\n",
      "Epoch 1 loss: 0.5932\n",
      "Epoch 1 loss: 0.5161\n",
      "Epoch 1 loss: 0.6289\n",
      "Epoch 1 loss: 0.6240\n",
      "Epoch 1 loss: 0.5633\n",
      "Epoch 1 loss: 0.5984\n",
      "Epoch 1 loss: 0.6162\n",
      "Epoch 1 loss: 0.6140\n",
      "Epoch 1 loss: 0.5860\n",
      "Epoch 1 loss: 0.5713\n",
      "Epoch 1 loss: 0.5792\n",
      "Epoch 1 loss: 0.6137\n",
      "Epoch 1 loss: 0.5647\n",
      "Epoch 1 loss: 0.5743\n",
      "Epoch 1 loss: 0.6161\n",
      "Epoch 1 loss: 0.5847\n",
      "Epoch 1 loss: 0.6302\n",
      "Epoch 1 loss: 0.5491\n",
      "Epoch 1 loss: 0.6148\n",
      "Epoch 1 loss: 0.5971\n",
      "Epoch 1 loss: 0.5849\n",
      "Epoch 1 loss: 0.5906\n",
      "Epoch 1 loss: 0.5455\n",
      "Epoch 1 loss: 0.5599\n",
      "Epoch 1 loss: 0.5633\n",
      "Epoch 1 loss: 0.6059\n",
      "Epoch 1 loss: 0.5798\n",
      "Epoch 1 loss: 0.5977\n",
      "Epoch 1 loss: 0.5595\n",
      "Epoch 1 loss: 0.5454\n",
      "Epoch 1 loss: 0.5690\n",
      "Epoch 1 loss: 0.5665\n",
      "Epoch 1 loss: 0.6240\n",
      "Epoch 1 loss: 0.5675\n",
      "Epoch 1 loss: 0.5675\n",
      "Epoch 1 loss: 0.5667\n",
      "Epoch 1 loss: 0.6122\n",
      "Epoch 1 loss: 0.6054\n",
      "Epoch 1 loss: 0.5909\n",
      "Epoch 1 loss: 0.5935\n",
      "Epoch 1 loss: 0.5844\n",
      "Epoch 1 loss: 0.5637\n",
      "Epoch 1 loss: 0.5606\n",
      "Epoch 1 loss: 0.5697\n",
      "Epoch 1 loss: 0.6012\n",
      "Epoch 1 loss: 0.6031\n",
      "Epoch 1 loss: 0.6202\n",
      "Epoch 1 loss: 0.5634\n",
      "Epoch 1 loss: 0.6094\n",
      "Epoch 1 loss: 0.5409\n",
      "Epoch 1 loss: 0.5652\n",
      "Epoch 1 loss: 0.5390\n",
      "Epoch 1 loss: 0.6093\n",
      "Epoch 1 loss: 0.5456\n",
      "Epoch 1 loss: 0.5832\n",
      "Epoch 1 loss: 0.5348\n",
      "Epoch 1 loss: 0.6442\n",
      "Epoch 1 loss: 0.5715\n",
      "Epoch 1 loss: 0.5480\n",
      "Epoch 1 loss: 0.5663\n",
      "Epoch 1 loss: 0.6254\n",
      "Epoch 1 loss: 0.6017\n",
      "Epoch 1 loss: 0.5527\n",
      "Epoch 1 loss: 0.5824\n",
      "Epoch 1 loss: 0.5926\n",
      "Epoch 1 loss: 0.5770\n",
      "Epoch 1 loss: 0.5768\n",
      "Epoch 1 loss: 0.6186\n",
      "Epoch 1 loss: 0.5525\n",
      "Epoch 1 loss: 0.5637\n",
      "Epoch 1 loss: 0.5652\n",
      "Epoch 1 loss: 0.6268\n",
      "Epoch 1 loss: 0.5686\n",
      "Epoch 1 loss: 0.5630\n",
      "Epoch 1 loss: 0.5664\n",
      "Epoch 1 loss: 0.5533\n",
      "Epoch 1 loss: 0.5665\n",
      "Epoch 1 loss: 0.5895\n",
      "Epoch 1 loss: 0.6137\n",
      "Epoch 1 loss: 0.5500\n",
      "Epoch 1 loss: 0.5428\n",
      "Epoch 1 loss: 0.5528\n",
      "Epoch 1 loss: 0.5865\n",
      "Epoch 1 loss: 0.5841\n",
      "Epoch 1 loss: 0.5848\n",
      "Epoch 1 loss: 0.5628\n",
      "Epoch 1 loss: 0.5906\n",
      "Epoch 1 loss: 0.5799\n",
      "Epoch 1 loss: 0.6005\n",
      "Epoch 1 loss: 0.6144\n",
      "Epoch 1 loss: 0.5592\n",
      "Epoch 1 loss: 0.5610\n",
      "Epoch 1 loss: 0.5740\n",
      "Epoch 1 loss: 0.6000\n",
      "Epoch 1 loss: 0.6113\n",
      "Epoch 1 loss: 0.5440\n",
      "Epoch 1 loss: 0.6279\n",
      "Epoch 1 loss: 0.6077\n",
      "Epoch 1 loss: 0.6012\n",
      "Epoch 1 loss: 0.5811\n",
      "Epoch 1 loss: 0.5780\n",
      "Epoch 1 loss: 0.5709\n",
      "Epoch 1 loss: 0.5849\n",
      "Epoch 1 loss: 0.5716\n",
      "Epoch 1 loss: 0.6133\n",
      "Epoch 1 loss: 0.5819\n",
      "Epoch 1 loss: 0.6252\n",
      "Epoch 1 loss: 0.6088\n",
      "Epoch 1 loss: 0.5689\n",
      "Epoch 1 loss: 0.5357\n",
      "Epoch 1 loss: 0.5617\n",
      "Epoch 1 loss: 0.5625\n",
      "Epoch 1 loss: 0.5656\n",
      "Epoch 1 loss: 0.6283\n",
      "Epoch 1 loss: 0.6118\n",
      "Epoch 1 loss: 0.6030\n",
      "Epoch 1 loss: 0.6495\n",
      "Epoch 1 loss: 0.5334\n",
      "Epoch 1 loss: 0.5657\n",
      "Epoch 1 loss: 0.6172\n",
      "Epoch 1 loss: 0.6173\n",
      "Epoch 1 loss: 0.5437\n",
      "Epoch 1 loss: 0.5765\n",
      "Epoch 1 loss: 0.5528\n",
      "Epoch 1 loss: 0.5818\n",
      "Epoch 1 loss: 0.6005\n",
      "Epoch 1 loss: 0.5651\n",
      "Epoch 1 loss: 0.5762\n",
      "Epoch 1 loss: 0.5523\n",
      "Epoch 1 loss: 0.5812\n",
      "Epoch 1 loss: 0.5850\n",
      "Epoch 1 loss: 0.6003\n",
      "Epoch 1 loss: 0.5204\n",
      "Epoch 1 loss: 0.5691\n",
      "Epoch 1 loss: 0.5513\n",
      "Epoch 1 loss: 0.5424\n",
      "Epoch 1 loss: 0.5621\n",
      "Epoch 1 loss: 0.5667\n",
      "Epoch 1 loss: 0.5567\n",
      "Epoch 1 loss: 0.5763\n",
      "Epoch 1 loss: 0.5702\n",
      "Epoch 1 loss: 0.5977\n",
      "Epoch 1 loss: 0.5862\n",
      "Epoch 1 loss: 0.5810\n",
      "Epoch 1 loss: 0.5467\n",
      "Epoch 1 loss: 0.5515\n",
      "Epoch 1 loss: 0.5829\n",
      "Epoch 1 loss: 0.5271\n",
      "Epoch 1 loss: 0.6310\n",
      "Epoch 1 loss: 0.5377\n",
      "Epoch 1 loss: 0.5330\n",
      "Epoch 1 loss: 0.5613\n",
      "Epoch 1 loss: 0.6130\n",
      "Epoch 1 loss: 0.5816\n",
      "Epoch 1 loss: 0.5863\n",
      "Epoch 1 loss: 0.6211\n",
      "Epoch 1 loss: 0.5638\n",
      "Epoch 1 loss: 0.5932\n",
      "Epoch 1 loss: 0.5951\n",
      "Epoch 1 loss: 0.5721\n",
      "Epoch 1 loss: 0.6082\n",
      "Epoch 1 loss: 0.5250\n",
      "Epoch 1 loss: 0.6056\n",
      "Epoch 1 loss: 0.5561\n",
      "Epoch 1 loss: 0.5580\n",
      "Epoch 1 loss: 0.5556\n",
      "Epoch 1 loss: 0.6131\n",
      "Epoch 1 loss: 0.5731\n",
      "Epoch 1 loss: 0.6129\n",
      "Epoch 1 loss: 0.5951\n",
      "Epoch 1 loss: 0.5657\n",
      "Epoch 1 loss: 0.5548\n",
      "Epoch 1 loss: 0.5543\n",
      "Epoch 1 loss: 0.5494\n",
      "Epoch 1 loss: 0.5471\n",
      "Epoch 1 loss: 0.5943\n",
      "Epoch 1 loss: 0.5892\n",
      "Epoch 1 loss: 0.5539\n",
      "Epoch 1 loss: 0.6285\n",
      "Epoch 1 loss: 0.5383\n",
      "Epoch 1 loss: 0.5447\n",
      "Epoch 1 loss: 0.5951\n",
      "Epoch 1 loss: 0.5697\n",
      "Epoch 1 loss: 0.5923\n",
      "Epoch 1 loss: 0.5901\n",
      "Epoch 1 loss: 0.5987\n",
      "Epoch 1 loss: 0.5740\n",
      "Epoch 1 loss: 0.5472\n",
      "Epoch 1 loss: 0.5664\n",
      "Epoch 1 loss: 0.5697\n",
      "Epoch 1 loss: 0.5821\n",
      "Epoch 1 loss: 0.5692\n",
      "Epoch 1 loss: 0.5590\n",
      "Epoch 1 loss: 0.6103\n",
      "Epoch 1 loss: 0.5359\n",
      "Epoch 1 loss: 0.6194\n",
      "Epoch 1 loss: 0.5298\n",
      "Epoch 1 loss: 0.5698\n",
      "Epoch 1 loss: 0.5575\n",
      "Epoch 1 loss: 0.5799\n",
      "Epoch 1 loss: 0.5747\n",
      "Epoch 1 loss: 0.5408\n",
      "Epoch 1 loss: 0.5717\n",
      "Epoch 1 loss: 0.5574\n",
      "Epoch 1 loss: 0.5749\n",
      "Epoch 1 loss: 0.6082\n",
      "Epoch 1 loss: 0.5589\n",
      "Epoch 1 loss: 0.5602\n",
      "Epoch 1 loss: 0.5528\n",
      "Epoch 1 loss: 0.5808\n",
      "Epoch 1 loss: 0.5697\n",
      "Epoch 1 loss: 0.5412\n",
      "Epoch 1 loss: 0.5823\n",
      "Epoch 1 loss: 0.5987\n",
      "Epoch 1 loss: 0.5799\n",
      "Epoch 1 loss: 0.5531\n",
      "Epoch 1 loss: 0.5986\n",
      "Epoch 1 loss: 0.5725\n",
      "Epoch 1 loss: 0.5774\n",
      "Epoch 1 loss: 0.5849\n",
      "Epoch 1 loss: 0.5773\n",
      "Epoch 1 loss: 0.5707\n",
      "Epoch 1 loss: 0.5691\n",
      "Epoch 1 loss: 0.5424\n",
      "Epoch 1 loss: 0.5586\n",
      "Epoch 1 loss: 0.5916\n",
      "Epoch 1 loss: 0.5507\n",
      "Epoch 1 loss: 0.5720\n",
      "Epoch 1 loss: 0.5959\n",
      "Epoch 1 loss: 0.5350\n",
      "Epoch 1 loss: 0.5201\n",
      "Epoch 1 loss: 0.6003\n",
      "Epoch 1 loss: 0.5923\n",
      "Epoch 1 loss: 0.5841\n",
      "Epoch 1 loss: 0.5712\n",
      "Epoch 1 loss: 0.5969\n",
      "Epoch 1 loss: 0.5681\n",
      "Epoch 1 loss: 0.5506\n",
      "Epoch 1 loss: 0.5697\n",
      "Epoch 1 loss: 0.5775\n",
      "Epoch 1 loss: 0.5473\n",
      "Epoch 1 loss: 0.6011\n",
      "Epoch 1 loss: 0.5938\n",
      "Epoch 1 loss: 0.5508\n",
      "Epoch 1 loss: 0.5478\n",
      "Epoch 1 loss: 0.5629\n",
      "Epoch 1 loss: 0.5441\n",
      "Epoch 1 loss: 0.5278\n",
      "Epoch 1 loss: 0.5495\n",
      "Epoch 1 loss: 0.5330\n",
      "Epoch 1 loss: 0.5811\n",
      "Epoch 1 loss: 0.6200\n",
      "Epoch 1 loss: 0.5099\n",
      "Epoch 1 loss: 0.5785\n",
      "Epoch 1 loss: 0.5903\n",
      "Epoch 1 loss: 0.5636\n",
      "Epoch 1 loss: 0.5985\n",
      "Epoch 1 loss: 0.5799\n",
      "Epoch 1 loss: 0.5852\n",
      "Epoch 1 loss: 0.5571\n",
      "Epoch 1 loss: 0.5244\n",
      "Epoch 1 loss: 0.6064\n",
      "Epoch 1 loss: 0.6046\n",
      "Epoch 1 loss: 0.6033\n",
      "Epoch 1 loss: 0.5797\n",
      "Epoch 1 loss: 0.5592\n",
      "Epoch 1 loss: 0.5257\n",
      "Epoch 1 loss: 0.6155\n",
      "Epoch 1 loss: 0.5891\n",
      "Epoch 1 loss: 0.5724\n",
      "Epoch 1 loss: 0.5076\n",
      "Epoch 1 loss: 0.5317\n",
      "Epoch 1 loss: 0.5767\n",
      "Epoch 1 loss: 0.5622\n",
      "Epoch 1 loss: 0.6085\n",
      "Epoch 1 loss: 0.5888\n",
      "Epoch 1 loss: 0.5616\n",
      "Epoch 1 loss: 0.5952\n",
      "Epoch 1 loss: 0.5613\n",
      "Epoch 1 loss: 0.5697\n",
      "Epoch 1 loss: 0.5846\n",
      "Epoch 1 loss: 0.5859\n",
      "Epoch 1 loss: 0.5217\n",
      "Epoch 1 loss: 0.5818\n",
      "Epoch 1 loss: 0.4977\n",
      "Epoch 1 loss: 0.5340\n",
      "Epoch 1 loss: 0.5774\n",
      "Epoch 1 loss: 0.6163\n",
      "Epoch 1 loss: 0.5639\n",
      "Epoch 1 loss: 0.5389\n",
      "Epoch 1 loss: 0.5766\n",
      "Epoch 1 loss: 0.5499\n",
      "Epoch 1 loss: 0.5841\n",
      "Epoch 1 loss: 0.5959\n",
      "Epoch 1 loss: 0.5742\n",
      "Epoch 1 loss: 0.5375\n",
      "Epoch 1 loss: 0.5875\n",
      "Epoch 1 loss: 0.6002\n",
      "Epoch 1 loss: 0.5294\n",
      "Epoch 1 loss: 0.5818\n",
      "Epoch 1 loss: 0.5804\n",
      "Epoch 1 loss: 0.5603\n",
      "Epoch 1 loss: 0.5476\n",
      "Epoch 1 loss: 0.5512\n",
      "Epoch 1 loss: 0.5582\n",
      "Epoch 1 loss: 0.5566\n",
      "Epoch 1 loss: 0.5743\n",
      "Epoch 1 loss: 0.5612\n",
      "Epoch 1 loss: 0.5504\n",
      "Epoch 1 loss: 0.5264\n",
      "Epoch 1 loss: 0.5642\n",
      "Epoch 1 loss: 0.5732\n",
      "Epoch 1 loss: 0.5725\n",
      "Epoch 1 loss: 0.5894\n",
      "Epoch 1 loss: 0.5408\n",
      "Epoch 1 loss: 0.5777\n",
      "Epoch 1 loss: 0.5991\n",
      "Epoch 1 loss: 0.5867\n",
      "Epoch 1 loss: 0.5321\n",
      "Epoch 1 loss: 0.5157\n",
      "Epoch 1 loss: 0.5261\n",
      "Epoch 1 loss: 0.5742\n",
      "Epoch 1 loss: 0.5464\n",
      "Epoch 1 loss: 0.5614\n",
      "Epoch 1 loss: 0.5709\n",
      "Epoch 1 loss: 0.5515\n",
      "Epoch 1 loss: 0.5581\n",
      "Epoch 1 loss: 0.5520\n",
      "Epoch 1 loss: 0.5900\n",
      "Epoch 1 loss: 0.5320\n",
      "Epoch 1 loss: 0.5412\n",
      "Epoch 1 loss: 0.5469\n",
      "Epoch 1 loss: 0.5946\n",
      "Epoch 1 loss: 0.5720\n",
      "Epoch 1 loss: 0.5474\n",
      "Epoch 1 loss: 0.5744\n",
      "Epoch 1 loss: 0.5917\n",
      "Epoch 1 loss: 0.5462\n",
      "Epoch 1 loss: 0.4963\n",
      "Epoch 1 loss: 0.5009\n",
      "Epoch 1 loss: 0.6117\n",
      "Epoch 1 loss: 0.5468\n",
      "Epoch 1 loss: 0.6404\n",
      "Epoch 1 loss: 0.5408\n",
      "Epoch 1 loss: 0.5726\n",
      "Epoch 1 loss: 0.5665\n",
      "Epoch 1 loss: 0.5490\n",
      "Epoch 1 loss: 0.5578\n",
      "Epoch 1 loss: 0.5689\n",
      "Epoch 1 loss: 0.5529\n",
      "Epoch 1 loss: 0.5739\n",
      "Epoch 1 loss: 0.5399\n",
      "Epoch 1 loss: 0.5223\n",
      "Epoch 1 loss: 0.5950\n",
      "Epoch 1 loss: 0.5209\n",
      "Epoch 1 loss: 0.5558\n",
      "Epoch 1 loss: 0.5815\n",
      "Epoch 1 loss: 0.5677\n",
      "Epoch 1 loss: 0.5723\n",
      "Epoch 1 loss: 0.5483\n",
      "Epoch 1 loss: 0.5621\n",
      "Epoch 1 loss: 0.5365\n",
      "Epoch 1 loss: 0.5336\n",
      "Epoch 1 loss: 0.5530\n",
      "Epoch 1 loss: 0.5143\n",
      "Epoch 1 loss: 0.5954\n",
      "Epoch 1 loss: 0.5325\n",
      "Epoch 1 loss: 0.5840\n",
      "Epoch 1 loss: 0.5267\n",
      "Epoch 1 loss: 0.5739\n",
      "Epoch 1 loss: 0.5680\n",
      "Epoch 1 loss: 0.5241\n",
      "Epoch 1 loss: 0.5307\n",
      "Epoch 1 loss: 0.5622\n",
      "Epoch 1 loss: 0.5629\n",
      "Epoch 1 loss: 0.5512\n",
      "Epoch 1 loss: 0.5691\n",
      "Epoch 1 loss: 0.5644\n",
      "Epoch 1 loss: 0.5409\n",
      "Epoch 1 loss: 0.5658\n",
      "Epoch 1 loss: 0.5670\n",
      "Epoch 1 loss: 0.5050\n",
      "Epoch 1 loss: 0.5345\n",
      "Epoch 1 loss: 0.5737\n",
      "Epoch 1 loss: 0.5817\n",
      "Epoch 1 loss: 0.5614\n",
      "Epoch 1 loss: 0.4981\n",
      "Epoch 1 loss: 0.5918\n",
      "Epoch 1 loss: 0.5615\n",
      "Epoch 1 loss: 0.5862\n",
      "Epoch 1 loss: 0.5064\n",
      "Epoch 1 loss: 0.5418\n",
      "Epoch 1 loss: 0.5669\n",
      "Epoch 1 loss: 0.5337\n",
      "Epoch 1 loss: 0.5807\n",
      "Epoch 1 loss: 0.5269\n",
      "Epoch 1 loss: 0.5538\n",
      "Epoch 1 loss: 0.5722\n",
      "Epoch 1 loss: 0.5115\n",
      "Epoch 1 loss: 0.5268\n",
      "Epoch 1 loss: 0.5404\n",
      "Epoch 1 loss: 0.5109\n",
      "Epoch 1 loss: 0.5319\n",
      "Epoch 1 loss: 0.5355\n",
      "Epoch 1 loss: 0.5665\n",
      "Epoch 1 loss: 0.5140\n",
      "Epoch 1 loss: 0.5331\n",
      "Epoch 1 loss: 0.5349\n",
      "Epoch 1 loss: 0.5474\n",
      "Epoch 1 loss: 0.5169\n",
      "Epoch 1 loss: 0.5182\n",
      "Epoch 1 loss: 0.5322\n",
      "Epoch 1 loss: 0.5325\n",
      "Epoch 1 loss: 0.5505\n",
      "Epoch 1 loss: 0.5440\n",
      "Epoch 1 loss: 0.5108\n",
      "Epoch 1 loss: 0.5333\n",
      "Epoch 1 loss: 0.5389\n",
      "Epoch 1 loss: 0.5427\n",
      "Epoch 1 loss: 0.5813\n",
      "Epoch 1 loss: 0.5542\n",
      "Epoch 1 loss: 0.5541\n",
      "Epoch 1 loss: 0.5411\n",
      "Epoch 1 loss: 0.5252\n",
      "Epoch 1 loss: 0.5327\n",
      "Epoch 1 loss: 0.5285\n",
      "Epoch 1 loss: 0.5139\n",
      "Epoch 1 loss: 0.5652\n",
      "Epoch 1 loss: 0.5918\n",
      "Epoch 1 loss: 0.5657\n",
      "Epoch 1 loss: 0.5143\n",
      "Epoch 1 loss: 0.5321\n",
      "Epoch 1 loss: 0.5995\n",
      "Epoch 1 loss: 0.5593\n",
      "Epoch 1 loss: 0.5305\n",
      "Epoch 1 loss: 0.5344\n",
      "Epoch 1 loss: 0.5476\n",
      "Epoch 1 loss: 0.5194\n",
      "Epoch 1 loss: 0.5661\n",
      "Epoch 1 loss: 0.5381\n",
      "Epoch 1 loss: 0.5267\n",
      "Epoch 1 loss: 0.5652\n",
      "Epoch 1 loss: 0.5876\n",
      "Epoch 1 loss: 0.5415\n",
      "Epoch 1 loss: 0.5203\n",
      "Epoch 1 loss: 0.5374\n",
      "Epoch 1 loss: 0.5760\n",
      "Epoch 1 loss: 0.5787\n",
      "Epoch 1 loss: 0.5323\n",
      "Epoch 1 loss: 0.5739\n",
      "Epoch 1 loss: 0.5700\n",
      "Epoch 1 loss: 0.5911\n",
      "Epoch 1 loss: 0.5482\n",
      "Epoch 1 loss: 0.5528\n",
      "Epoch 1 loss: 0.6048\n",
      "Epoch 1 loss: 0.5873\n",
      "Epoch 1 loss: 0.5320\n",
      "Epoch 1 loss: 0.5546\n",
      "Epoch 1 loss: 0.5506\n",
      "Epoch 1 loss: 0.5482\n",
      "Epoch 1 loss: 0.5336\n",
      "Epoch 1 loss: 0.5903\n",
      "Epoch 1 loss: 0.5378\n",
      "Epoch 1 loss: 0.5228\n",
      "Epoch 1 loss: 0.5782\n",
      "Epoch 1 loss: 0.5038\n",
      "Epoch 1 loss: 0.5308\n",
      "Epoch 1 loss: 0.6027\n",
      "Epoch 1 loss: 0.5342\n",
      "Epoch 1 loss: 0.5558\n",
      "Epoch 1 loss: 0.5480\n",
      "Epoch 1 loss: 0.5495\n",
      "Epoch 1 loss: 0.5626\n",
      "Epoch 1 loss: 0.5407\n",
      "Epoch 1 loss: 0.5269\n",
      "Epoch 1 loss: 0.5101\n",
      "Epoch 1 loss: 0.5448\n",
      "Epoch 1 loss: 0.5138\n",
      "Epoch 1 loss: 0.5537\n",
      "Epoch 1 loss: 0.6059\n",
      "Epoch 1 loss: 0.5401\n",
      "Epoch 1 loss: 0.5588\n",
      "Epoch 1 loss: 0.5481\n",
      "Epoch 1 loss: 0.5577\n",
      "Epoch 1 loss: 0.5341\n",
      "Epoch 1 loss: 0.5361\n",
      "Epoch 1 loss: 0.5412\n",
      "Epoch 1 loss: 0.5872\n",
      "Epoch 1 loss: 0.4992\n",
      "Epoch 1 loss: 0.5690\n",
      "Epoch 1 loss: 0.6096\n",
      "Epoch 1 loss: 0.5593\n",
      "Epoch 1 loss: 0.5728\n",
      "Epoch 1 loss: 0.5984\n",
      "Epoch 1 loss: 0.5187\n",
      "Epoch 1 loss: 0.5712\n",
      "Epoch 1 loss: 0.5138\n",
      "Epoch 1 loss: 0.5218\n",
      "Epoch 1 loss: 0.5848\n",
      "Epoch 1 loss: 0.5533\n",
      "Epoch 1 loss: 0.5891\n",
      "Epoch 1 loss: 0.5230\n",
      "Epoch 1 loss: 0.4880\n",
      "Epoch 1 loss: 0.5201\n",
      "Epoch 1 loss: 0.5884\n",
      "Epoch 1 loss: 0.5748\n",
      "Epoch 1 loss: 0.5719\n",
      "Epoch 1 loss: 0.4981\n",
      "Epoch 1 loss: 0.4953\n",
      "Epoch 1 loss: 0.5531\n",
      "Epoch 1 loss: 0.5326\n",
      "Epoch 1 loss: 0.5029\n",
      "Epoch 1 loss: 0.5349\n",
      "Epoch 1 loss: 0.5691\n",
      "Epoch 1 loss: 0.5344\n",
      "Epoch 1 loss: 0.5694\n",
      "Epoch 1 loss: 0.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.5382\n",
      "Epoch 2 loss: 0.5330\n",
      "Epoch 2 loss: 0.5558\n",
      "Epoch 2 loss: 0.5407\n",
      "Epoch 2 loss: 0.5258\n",
      "Epoch 2 loss: 0.5708\n",
      "Epoch 2 loss: 0.5544\n",
      "Epoch 2 loss: 0.5077\n",
      "Epoch 2 loss: 0.5598\n",
      "Epoch 2 loss: 0.5517\n",
      "Epoch 2 loss: 0.5361\n",
      "Epoch 2 loss: 0.5298\n",
      "Epoch 2 loss: 0.5488\n",
      "Epoch 2 loss: 0.5323\n",
      "Epoch 2 loss: 0.5587\n",
      "Epoch 2 loss: 0.5505\n",
      "Epoch 2 loss: 0.5039\n",
      "Epoch 2 loss: 0.5585\n",
      "Epoch 2 loss: 0.5214\n",
      "Epoch 2 loss: 0.5340\n",
      "Epoch 2 loss: 0.5456\n",
      "Epoch 2 loss: 0.5607\n",
      "Epoch 2 loss: 0.5222\n",
      "Epoch 2 loss: 0.5495\n",
      "Epoch 2 loss: 0.5253\n",
      "Epoch 2 loss: 0.5140\n",
      "Epoch 2 loss: 0.5191\n",
      "Epoch 2 loss: 0.5536\n",
      "Epoch 2 loss: 0.5180\n",
      "Epoch 2 loss: 0.5791\n",
      "Epoch 2 loss: 0.5574\n",
      "Epoch 2 loss: 0.4667\n",
      "Epoch 2 loss: 0.5426\n",
      "Epoch 2 loss: 0.5482\n",
      "Epoch 2 loss: 0.6102\n",
      "Epoch 2 loss: 0.5304\n",
      "Epoch 2 loss: 0.5245\n",
      "Epoch 2 loss: 0.5152\n",
      "Epoch 2 loss: 0.5138\n",
      "Epoch 2 loss: 0.5357\n",
      "Epoch 2 loss: 0.5107\n",
      "Epoch 2 loss: 0.4903\n",
      "Epoch 2 loss: 0.4697\n",
      "Epoch 2 loss: 0.5194\n",
      "Epoch 2 loss: 0.5456\n",
      "Epoch 2 loss: 0.5268\n",
      "Epoch 2 loss: 0.5597\n",
      "Epoch 2 loss: 0.5379\n",
      "Epoch 2 loss: 0.6134\n",
      "Epoch 2 loss: 0.5106\n",
      "Epoch 2 loss: 0.5023\n",
      "Epoch 2 loss: 0.5571\n",
      "Epoch 2 loss: 0.4841\n",
      "Epoch 2 loss: 0.5750\n",
      "Epoch 2 loss: 0.5169\n",
      "Epoch 2 loss: 0.5095\n",
      "Epoch 2 loss: 0.5228\n",
      "Epoch 2 loss: 0.5287\n",
      "Epoch 2 loss: 0.6041\n",
      "Epoch 2 loss: 0.5275\n",
      "Epoch 2 loss: 0.5140\n",
      "Epoch 2 loss: 0.5452\n",
      "Epoch 2 loss: 0.5412\n",
      "Epoch 2 loss: 0.5656\n",
      "Epoch 2 loss: 0.5199\n",
      "Epoch 2 loss: 0.5610\n",
      "Epoch 2 loss: 0.5239\n",
      "Epoch 2 loss: 0.5732\n",
      "Epoch 2 loss: 0.5074\n",
      "Epoch 2 loss: 0.5409\n",
      "Epoch 2 loss: 0.4748\n",
      "Epoch 2 loss: 0.5011\n",
      "Epoch 2 loss: 0.4803\n",
      "Epoch 2 loss: 0.5248\n",
      "Epoch 2 loss: 0.5282\n",
      "Epoch 2 loss: 0.5181\n",
      "Epoch 2 loss: 0.5608\n",
      "Epoch 2 loss: 0.5540\n",
      "Epoch 2 loss: 0.5447\n",
      "Epoch 2 loss: 0.5126\n",
      "Epoch 2 loss: 0.5638\n",
      "Epoch 2 loss: 0.6016\n",
      "Epoch 2 loss: 0.5368\n",
      "Epoch 2 loss: 0.5708\n",
      "Epoch 2 loss: 0.5711\n",
      "Epoch 2 loss: 0.4798\n",
      "Epoch 2 loss: 0.5830\n",
      "Epoch 2 loss: 0.5016\n",
      "Epoch 2 loss: 0.5095\n",
      "Epoch 2 loss: 0.5020\n",
      "Epoch 2 loss: 0.5535\n",
      "Epoch 2 loss: 0.5199\n",
      "Epoch 2 loss: 0.4842\n",
      "Epoch 2 loss: 0.5187\n",
      "Epoch 2 loss: 0.5486\n",
      "Epoch 2 loss: 0.5134\n",
      "Epoch 2 loss: 0.5345\n",
      "Epoch 2 loss: 0.5532\n",
      "Epoch 2 loss: 0.5610\n",
      "Epoch 2 loss: 0.5452\n",
      "Epoch 2 loss: 0.4932\n",
      "Epoch 2 loss: 0.4932\n",
      "Epoch 2 loss: 0.5147\n",
      "Epoch 2 loss: 0.5318\n",
      "Epoch 2 loss: 0.4985\n",
      "Epoch 2 loss: 0.5195\n",
      "Epoch 2 loss: 0.5388\n",
      "Epoch 2 loss: 0.4674\n",
      "Epoch 2 loss: 0.5540\n",
      "Epoch 2 loss: 0.5240\n",
      "Epoch 2 loss: 0.5902\n",
      "Epoch 2 loss: 0.5250\n",
      "Epoch 2 loss: 0.4919\n",
      "Epoch 2 loss: 0.5130\n",
      "Epoch 2 loss: 0.5290\n",
      "Epoch 2 loss: 0.5482\n",
      "Epoch 2 loss: 0.5225\n",
      "Epoch 2 loss: 0.5318\n",
      "Epoch 2 loss: 0.5217\n",
      "Epoch 2 loss: 0.5565\n",
      "Epoch 2 loss: 0.5391\n",
      "Epoch 2 loss: 0.4431\n",
      "Epoch 2 loss: 0.4961\n",
      "Epoch 2 loss: 0.5547\n",
      "Epoch 2 loss: 0.5436\n",
      "Epoch 2 loss: 0.4808\n",
      "Epoch 2 loss: 0.4882\n",
      "Epoch 2 loss: 0.4933\n",
      "Epoch 2 loss: 0.5058\n",
      "Epoch 2 loss: 0.5207\n",
      "Epoch 2 loss: 0.4871\n",
      "Epoch 2 loss: 0.5216\n",
      "Epoch 2 loss: 0.5108\n",
      "Epoch 2 loss: 0.5311\n",
      "Epoch 2 loss: 0.4898\n",
      "Epoch 2 loss: 0.4895\n",
      "Epoch 2 loss: 0.5388\n",
      "Epoch 2 loss: 0.5400\n",
      "Epoch 2 loss: 0.5866\n",
      "Epoch 2 loss: 0.5553\n",
      "Epoch 2 loss: 0.5135\n",
      "Epoch 2 loss: 0.5512\n",
      "Epoch 2 loss: 0.5482\n",
      "Epoch 2 loss: 0.5339\n",
      "Epoch 2 loss: 0.5156\n",
      "Epoch 2 loss: 0.5431\n",
      "Epoch 2 loss: 0.4700\n",
      "Epoch 2 loss: 0.5459\n",
      "Epoch 2 loss: 0.5390\n",
      "Epoch 2 loss: 0.5377\n",
      "Epoch 2 loss: 0.5328\n",
      "Epoch 2 loss: 0.5317\n",
      "Epoch 2 loss: 0.5400\n",
      "Epoch 2 loss: 0.5689\n",
      "Epoch 2 loss: 0.5272\n",
      "Epoch 2 loss: 0.5580\n",
      "Epoch 2 loss: 0.5315\n",
      "Epoch 2 loss: 0.5489\n",
      "Epoch 2 loss: 0.4848\n",
      "Epoch 2 loss: 0.5117\n",
      "Epoch 2 loss: 0.4852\n",
      "Epoch 2 loss: 0.5267\n",
      "Epoch 2 loss: 0.5313\n",
      "Epoch 2 loss: 0.5011\n",
      "Epoch 2 loss: 0.5074\n",
      "Epoch 2 loss: 0.5190\n",
      "Epoch 2 loss: 0.5314\n",
      "Epoch 2 loss: 0.5708\n",
      "Epoch 2 loss: 0.5406\n",
      "Epoch 2 loss: 0.5418\n",
      "Epoch 2 loss: 0.5646\n",
      "Epoch 2 loss: 0.5266\n",
      "Epoch 2 loss: 0.4434\n",
      "Epoch 2 loss: 0.5221\n",
      "Epoch 2 loss: 0.5042\n",
      "Epoch 2 loss: 0.5502\n",
      "Epoch 2 loss: 0.5542\n",
      "Epoch 2 loss: 0.4868\n",
      "Epoch 2 loss: 0.5403\n",
      "Epoch 2 loss: 0.4951\n",
      "Epoch 2 loss: 0.4972\n",
      "Epoch 2 loss: 0.4900\n",
      "Epoch 2 loss: 0.4707\n",
      "Epoch 2 loss: 0.4916\n",
      "Epoch 2 loss: 0.4948\n",
      "Epoch 2 loss: 0.4656\n",
      "Epoch 2 loss: 0.5281\n",
      "Epoch 2 loss: 0.5593\n",
      "Epoch 2 loss: 0.5041\n",
      "Epoch 2 loss: 0.4868\n",
      "Epoch 2 loss: 0.5739\n",
      "Epoch 2 loss: 0.5266\n",
      "Epoch 2 loss: 0.5335\n",
      "Epoch 2 loss: 0.5233\n",
      "Epoch 2 loss: 0.5297\n",
      "Epoch 2 loss: 0.5907\n",
      "Epoch 2 loss: 0.5339\n",
      "Epoch 2 loss: 0.5364\n",
      "Epoch 2 loss: 0.5544\n",
      "Epoch 2 loss: 0.5024\n",
      "Epoch 2 loss: 0.4758\n",
      "Epoch 2 loss: 0.5287\n",
      "Epoch 2 loss: 0.5116\n",
      "Epoch 2 loss: 0.5811\n",
      "Epoch 2 loss: 0.5528\n",
      "Epoch 2 loss: 0.4510\n",
      "Epoch 2 loss: 0.5618\n",
      "Epoch 2 loss: 0.5699\n",
      "Epoch 2 loss: 0.5524\n",
      "Epoch 2 loss: 0.5239\n",
      "Epoch 2 loss: 0.4851\n",
      "Epoch 2 loss: 0.5131\n",
      "Epoch 2 loss: 0.5406\n",
      "Epoch 2 loss: 0.5352\n",
      "Epoch 2 loss: 0.5687\n",
      "Epoch 2 loss: 0.4704\n",
      "Epoch 2 loss: 0.5272\n",
      "Epoch 2 loss: 0.5017\n",
      "Epoch 2 loss: 0.5176\n",
      "Epoch 2 loss: 0.5347\n",
      "Epoch 2 loss: 0.5535\n",
      "Epoch 2 loss: 0.5407\n",
      "Epoch 2 loss: 0.5988\n",
      "Epoch 2 loss: 0.4668\n",
      "Epoch 2 loss: 0.4642\n",
      "Epoch 2 loss: 0.5465\n",
      "Epoch 2 loss: 0.4391\n",
      "Epoch 2 loss: 0.5493\n",
      "Epoch 2 loss: 0.4850\n",
      "Epoch 2 loss: 0.5094\n",
      "Epoch 2 loss: 0.5650\n",
      "Epoch 2 loss: 0.5130\n",
      "Epoch 2 loss: 0.5002\n",
      "Epoch 2 loss: 0.5021\n",
      "Epoch 2 loss: 0.5040\n",
      "Epoch 2 loss: 0.5352\n",
      "Epoch 2 loss: 0.5371\n",
      "Epoch 2 loss: 0.5739\n",
      "Epoch 2 loss: 0.5087\n",
      "Epoch 2 loss: 0.4917\n",
      "Epoch 2 loss: 0.5221\n",
      "Epoch 2 loss: 0.5072\n",
      "Epoch 2 loss: 0.5185\n",
      "Epoch 2 loss: 0.4851\n",
      "Epoch 2 loss: 0.4967\n",
      "Epoch 2 loss: 0.4932\n",
      "Epoch 2 loss: 0.5419\n",
      "Epoch 2 loss: 0.5646\n",
      "Epoch 2 loss: 0.5295\n",
      "Epoch 2 loss: 0.5102\n",
      "Epoch 2 loss: 0.5618\n",
      "Epoch 2 loss: 0.5064\n",
      "Epoch 2 loss: 0.5249\n",
      "Epoch 2 loss: 0.5042\n",
      "Epoch 2 loss: 0.5169\n",
      "Epoch 2 loss: 0.5311\n",
      "Epoch 2 loss: 0.4867\n",
      "Epoch 2 loss: 0.5286\n",
      "Epoch 2 loss: 0.5566\n",
      "Epoch 2 loss: 0.4816\n",
      "Epoch 2 loss: 0.5435\n",
      "Epoch 2 loss: 0.5637\n",
      "Epoch 2 loss: 0.5029\n",
      "Epoch 2 loss: 0.5365\n",
      "Epoch 2 loss: 0.4898\n",
      "Epoch 2 loss: 0.4676\n",
      "Epoch 2 loss: 0.5238\n",
      "Epoch 2 loss: 0.4764\n",
      "Epoch 2 loss: 0.5138\n",
      "Epoch 2 loss: 0.5440\n",
      "Epoch 2 loss: 0.5055\n",
      "Epoch 2 loss: 0.4894\n",
      "Epoch 2 loss: 0.5505\n",
      "Epoch 2 loss: 0.5277\n",
      "Epoch 2 loss: 0.5318\n",
      "Epoch 2 loss: 0.4850\n",
      "Epoch 2 loss: 0.4847\n",
      "Epoch 2 loss: 0.5307\n",
      "Epoch 2 loss: 0.5005\n",
      "Epoch 2 loss: 0.4924\n",
      "Epoch 2 loss: 0.5329\n",
      "Epoch 2 loss: 0.4367\n",
      "Epoch 2 loss: 0.5329\n",
      "Epoch 2 loss: 0.5012\n",
      "Epoch 2 loss: 0.5053\n",
      "Epoch 2 loss: 0.5137\n",
      "Epoch 2 loss: 0.5053\n",
      "Epoch 2 loss: 0.5023\n",
      "Epoch 2 loss: 0.5244\n",
      "Epoch 2 loss: 0.5084\n",
      "Epoch 2 loss: 0.4882\n",
      "Epoch 2 loss: 0.4949\n",
      "Epoch 2 loss: 0.4974\n",
      "Epoch 2 loss: 0.4670\n",
      "Epoch 2 loss: 0.4713\n",
      "Epoch 2 loss: 0.5199\n",
      "Epoch 2 loss: 0.5265\n",
      "Epoch 2 loss: 0.4801\n",
      "Epoch 2 loss: 0.5320\n",
      "Epoch 2 loss: 0.4831\n",
      "Epoch 2 loss: 0.5476\n",
      "Epoch 2 loss: 0.4704\n",
      "Epoch 2 loss: 0.5086\n",
      "Epoch 2 loss: 0.5043\n",
      "Epoch 2 loss: 0.5122\n",
      "Epoch 2 loss: 0.4947\n",
      "Epoch 2 loss: 0.4649\n",
      "Epoch 2 loss: 0.5273\n",
      "Epoch 2 loss: 0.4481\n",
      "Epoch 2 loss: 0.4883\n",
      "Epoch 2 loss: 0.5321\n",
      "Epoch 2 loss: 0.4685\n",
      "Epoch 2 loss: 0.5385\n",
      "Epoch 2 loss: 0.5239\n",
      "Epoch 2 loss: 0.5620\n",
      "Epoch 2 loss: 0.5617\n",
      "Epoch 2 loss: 0.5387\n",
      "Epoch 2 loss: 0.4849\n",
      "Epoch 2 loss: 0.5328\n",
      "Epoch 2 loss: 0.5411\n",
      "Epoch 2 loss: 0.5058\n",
      "Epoch 2 loss: 0.5266\n",
      "Epoch 2 loss: 0.4857\n",
      "Epoch 2 loss: 0.5654\n",
      "Epoch 2 loss: 0.4749\n",
      "Epoch 2 loss: 0.5089\n",
      "Epoch 2 loss: 0.5301\n",
      "Epoch 2 loss: 0.5093\n",
      "Epoch 2 loss: 0.5673\n",
      "Epoch 2 loss: 0.5123\n",
      "Epoch 2 loss: 0.5200\n",
      "Epoch 2 loss: 0.5852\n",
      "Epoch 2 loss: 0.4919\n",
      "Epoch 2 loss: 0.5062\n",
      "Epoch 2 loss: 0.5397\n",
      "Epoch 2 loss: 0.5125\n",
      "Epoch 2 loss: 0.5340\n",
      "Epoch 2 loss: 0.4800\n",
      "Epoch 2 loss: 0.5381\n",
      "Epoch 2 loss: 0.5133\n",
      "Epoch 2 loss: 0.5073\n",
      "Epoch 2 loss: 0.6011\n",
      "Epoch 2 loss: 0.5145\n",
      "Epoch 2 loss: 0.4866\n",
      "Epoch 2 loss: 0.4962\n",
      "Epoch 2 loss: 0.4702\n",
      "Epoch 2 loss: 0.5485\n",
      "Epoch 2 loss: 0.4940\n",
      "Epoch 2 loss: 0.5351\n",
      "Epoch 2 loss: 0.5432\n",
      "Epoch 2 loss: 0.5077\n",
      "Epoch 2 loss: 0.5396\n",
      "Epoch 2 loss: 0.5290\n",
      "Epoch 2 loss: 0.5208\n",
      "Epoch 2 loss: 0.5220\n",
      "Epoch 2 loss: 0.4773\n",
      "Epoch 2 loss: 0.4879\n",
      "Epoch 2 loss: 0.4903\n",
      "Epoch 2 loss: 0.4876\n",
      "Epoch 2 loss: 0.5324\n",
      "Epoch 2 loss: 0.5300\n",
      "Epoch 2 loss: 0.5020\n",
      "Epoch 2 loss: 0.4991\n",
      "Epoch 2 loss: 0.5037\n",
      "Epoch 2 loss: 0.4690\n",
      "Epoch 2 loss: 0.4762\n",
      "Epoch 2 loss: 0.5682\n",
      "Epoch 2 loss: 0.4612\n",
      "Epoch 2 loss: 0.5013\n",
      "Epoch 2 loss: 0.5245\n",
      "Epoch 2 loss: 0.5277\n",
      "Epoch 2 loss: 0.5480\n",
      "Epoch 2 loss: 0.5011\n",
      "Epoch 2 loss: 0.4740\n",
      "Epoch 2 loss: 0.4689\n",
      "Epoch 2 loss: 0.4959\n",
      "Epoch 2 loss: 0.4983\n",
      "Epoch 2 loss: 0.4688\n",
      "Epoch 2 loss: 0.5403\n",
      "Epoch 2 loss: 0.5043\n",
      "Epoch 2 loss: 0.4501\n",
      "Epoch 2 loss: 0.4458\n",
      "Epoch 2 loss: 0.4483\n",
      "Epoch 2 loss: 0.5316\n",
      "Epoch 2 loss: 0.5524\n",
      "Epoch 2 loss: 0.4630\n",
      "Epoch 2 loss: 0.4965\n",
      "Epoch 2 loss: 0.4830\n",
      "Epoch 2 loss: 0.4789\n",
      "Epoch 2 loss: 0.5093\n",
      "Epoch 2 loss: 0.4447\n",
      "Epoch 2 loss: 0.5086\n",
      "Epoch 2 loss: 0.5019\n",
      "Epoch 2 loss: 0.5158\n",
      "Epoch 2 loss: 0.4875\n",
      "Epoch 2 loss: 0.4848\n",
      "Epoch 2 loss: 0.4691\n",
      "Epoch 2 loss: 0.5364\n",
      "Epoch 2 loss: 0.5813\n",
      "Epoch 2 loss: 0.4924\n",
      "Epoch 2 loss: 0.5291\n",
      "Epoch 2 loss: 0.4725\n",
      "Epoch 2 loss: 0.4750\n",
      "Epoch 2 loss: 0.4803\n",
      "Epoch 2 loss: 0.4885\n",
      "Epoch 2 loss: 0.4800\n",
      "Epoch 2 loss: 0.5377\n",
      "Epoch 2 loss: 0.5362\n",
      "Epoch 2 loss: 0.4312\n",
      "Epoch 2 loss: 0.5295\n",
      "Epoch 2 loss: 0.4624\n",
      "Epoch 2 loss: 0.4880\n",
      "Epoch 2 loss: 0.5076\n",
      "Epoch 2 loss: 0.4843\n",
      "Epoch 2 loss: 0.5200\n",
      "Epoch 2 loss: 0.4591\n",
      "Epoch 2 loss: 0.5174\n",
      "Epoch 2 loss: 0.4614\n",
      "Epoch 2 loss: 0.4885\n",
      "Epoch 2 loss: 0.4898\n",
      "Epoch 2 loss: 0.5102\n",
      "Epoch 2 loss: 0.5214\n",
      "Epoch 2 loss: 0.5542\n",
      "Epoch 2 loss: 0.4664\n",
      "Epoch 2 loss: 0.5849\n",
      "Epoch 2 loss: 0.5018\n",
      "Epoch 2 loss: 0.5623\n",
      "Epoch 2 loss: 0.4695\n",
      "Epoch 2 loss: 0.5298\n",
      "Epoch 2 loss: 0.4987\n",
      "Epoch 2 loss: 0.4927\n",
      "Epoch 2 loss: 0.4837\n",
      "Epoch 2 loss: 0.4938\n",
      "Epoch 2 loss: 0.4423\n",
      "Epoch 2 loss: 0.4956\n",
      "Epoch 2 loss: 0.5044\n",
      "Epoch 2 loss: 0.4430\n",
      "Epoch 2 loss: 0.4934\n",
      "Epoch 2 loss: 0.4757\n",
      "Epoch 2 loss: 0.4732\n",
      "Epoch 2 loss: 0.5199\n",
      "Epoch 2 loss: 0.4647\n",
      "Epoch 2 loss: 0.4810\n",
      "Epoch 2 loss: 0.5674\n",
      "Epoch 2 loss: 0.5224\n",
      "Epoch 2 loss: 0.5071\n",
      "Epoch 2 loss: 0.4381\n",
      "Epoch 2 loss: 0.4709\n",
      "Epoch 2 loss: 0.5364\n",
      "Epoch 2 loss: 0.5141\n",
      "Epoch 2 loss: 0.4294\n",
      "Epoch 2 loss: 0.5269\n",
      "Epoch 2 loss: 0.4822\n",
      "Epoch 2 loss: 0.5268\n",
      "Epoch 2 loss: 0.5099\n",
      "Epoch 2 loss: 0.5208\n",
      "Epoch 2 loss: 0.5542\n",
      "Epoch 2 loss: 0.5105\n",
      "Epoch 2 loss: 0.5322\n",
      "Epoch 2 loss: 0.4852\n",
      "Epoch 2 loss: 0.4386\n",
      "Epoch 2 loss: 0.5358\n",
      "Epoch 2 loss: 0.5270\n",
      "Epoch 2 loss: 0.4902\n",
      "Epoch 2 loss: 0.4888\n",
      "Epoch 2 loss: 0.5125\n",
      "Epoch 2 loss: 0.4704\n",
      "Epoch 2 loss: 0.5043\n",
      "Epoch 2 loss: 0.5291\n",
      "Epoch 2 loss: 0.4691\n",
      "Epoch 2 loss: 0.4738\n",
      "Epoch 2 loss: 0.4879\n",
      "Epoch 2 loss: 0.4653\n",
      "Epoch 2 loss: 0.5798\n",
      "Epoch 2 loss: 0.4760\n",
      "Epoch 2 loss: 0.4913\n",
      "Epoch 2 loss: 0.4651\n",
      "Epoch 2 loss: 0.5319\n",
      "Epoch 2 loss: 0.4418\n",
      "Epoch 2 loss: 0.4680\n",
      "Epoch 2 loss: 0.5225\n",
      "Epoch 2 loss: 0.5350\n",
      "Epoch 2 loss: 0.5031\n",
      "Epoch 2 loss: 0.4384\n",
      "Epoch 2 loss: 0.4921\n",
      "Epoch 2 loss: 0.4919\n",
      "Epoch 2 loss: 0.4838\n",
      "Epoch 2 loss: 0.4512\n",
      "Epoch 2 loss: 0.4619\n",
      "Epoch 2 loss: 0.5110\n",
      "Epoch 2 loss: 0.4830\n",
      "Epoch 2 loss: 0.4305\n",
      "Epoch 2 loss: 0.5249\n",
      "Epoch 2 loss: 0.4809\n",
      "Epoch 2 loss: 0.5225\n",
      "Epoch 2 loss: 0.4859\n",
      "Epoch 2 loss: 0.4634\n",
      "Epoch 2 loss: 0.4948\n",
      "Epoch 2 loss: 0.4371\n",
      "Epoch 2 loss: 0.5091\n",
      "Epoch 2 loss: 0.5035\n",
      "Epoch 2 loss: 0.4865\n",
      "Epoch 2 loss: 0.4485\n",
      "Epoch 2 loss: 0.4732\n",
      "Epoch 2 loss: 0.4086\n",
      "Epoch 2 loss: 0.4887\n",
      "Epoch 2 loss: 0.5391\n",
      "Epoch 2 loss: 0.4237\n",
      "Epoch 2 loss: 0.4942\n",
      "Epoch 2 loss: 0.5549\n",
      "Epoch 2 loss: 0.5311\n",
      "Epoch 2 loss: 0.4972\n",
      "Epoch 2 loss: 0.4641\n",
      "Epoch 2 loss: 0.4826\n",
      "Epoch 2 loss: 0.5028\n",
      "Epoch 2 loss: 0.4899\n",
      "Epoch 2 loss: 0.5094\n",
      "Epoch 2 loss: 0.5079\n",
      "Epoch 2 loss: 0.4759\n",
      "Epoch 2 loss: 0.4636\n",
      "Epoch 2 loss: 0.5238\n",
      "Epoch 2 loss: 0.4920\n",
      "Epoch 2 loss: 0.5101\n",
      "Epoch 2 loss: 0.4959\n",
      "Epoch 2 loss: 0.4674\n",
      "Epoch 2 loss: 0.4282\n",
      "Epoch 2 loss: 0.5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.4784\n",
      "Epoch 3 loss: 0.4720\n",
      "Epoch 3 loss: 0.5012\n",
      "Epoch 3 loss: 0.5288\n",
      "Epoch 3 loss: 0.4397\n",
      "Epoch 3 loss: 0.5294\n",
      "Epoch 3 loss: 0.4346\n",
      "Epoch 3 loss: 0.4964\n",
      "Epoch 3 loss: 0.4996\n",
      "Epoch 3 loss: 0.5161\n",
      "Epoch 3 loss: 0.4610\n",
      "Epoch 3 loss: 0.4833\n",
      "Epoch 3 loss: 0.4662\n",
      "Epoch 3 loss: 0.4588\n",
      "Epoch 3 loss: 0.4414\n",
      "Epoch 3 loss: 0.5200\n",
      "Epoch 3 loss: 0.4402\n",
      "Epoch 3 loss: 0.5021\n",
      "Epoch 3 loss: 0.5199\n",
      "Epoch 3 loss: 0.5036\n",
      "Epoch 3 loss: 0.4618\n",
      "Epoch 3 loss: 0.5520\n",
      "Epoch 3 loss: 0.4046\n",
      "Epoch 3 loss: 0.4573\n",
      "Epoch 3 loss: 0.4834\n",
      "Epoch 3 loss: 0.5029\n",
      "Epoch 3 loss: 0.4898\n",
      "Epoch 3 loss: 0.4871\n",
      "Epoch 3 loss: 0.4923\n",
      "Epoch 3 loss: 0.5338\n",
      "Epoch 3 loss: 0.4848\n",
      "Epoch 3 loss: 0.4407\n",
      "Epoch 3 loss: 0.4416\n",
      "Epoch 3 loss: 0.5547\n",
      "Epoch 3 loss: 0.4530\n",
      "Epoch 3 loss: 0.4785\n",
      "Epoch 3 loss: 0.4599\n",
      "Epoch 3 loss: 0.4828\n",
      "Epoch 3 loss: 0.4413\n",
      "Epoch 3 loss: 0.4099\n",
      "Epoch 3 loss: 0.4506\n",
      "Epoch 3 loss: 0.5017\n",
      "Epoch 3 loss: 0.5517\n",
      "Epoch 3 loss: 0.4694\n",
      "Epoch 3 loss: 0.5008\n",
      "Epoch 3 loss: 0.4683\n",
      "Epoch 3 loss: 0.4850\n",
      "Epoch 3 loss: 0.4767\n",
      "Epoch 3 loss: 0.4689\n",
      "Epoch 3 loss: 0.5377\n",
      "Epoch 3 loss: 0.5016\n",
      "Epoch 3 loss: 0.5138\n",
      "Epoch 3 loss: 0.4741\n",
      "Epoch 3 loss: 0.4550\n",
      "Epoch 3 loss: 0.5118\n",
      "Epoch 3 loss: 0.4368\n",
      "Epoch 3 loss: 0.4748\n",
      "Epoch 3 loss: 0.4741\n",
      "Epoch 3 loss: 0.4608\n",
      "Epoch 3 loss: 0.4775\n",
      "Epoch 3 loss: 0.4622\n",
      "Epoch 3 loss: 0.4512\n",
      "Epoch 3 loss: 0.5045\n",
      "Epoch 3 loss: 0.5375\n",
      "Epoch 3 loss: 0.4780\n",
      "Epoch 3 loss: 0.5023\n",
      "Epoch 3 loss: 0.4861\n",
      "Epoch 3 loss: 0.4796\n",
      "Epoch 3 loss: 0.4492\n",
      "Epoch 3 loss: 0.4170\n",
      "Epoch 3 loss: 0.4795\n",
      "Epoch 3 loss: 0.5065\n",
      "Epoch 3 loss: 0.5428\n",
      "Epoch 3 loss: 0.4603\n",
      "Epoch 3 loss: 0.5108\n",
      "Epoch 3 loss: 0.4944\n",
      "Epoch 3 loss: 0.4632\n",
      "Epoch 3 loss: 0.4868\n",
      "Epoch 3 loss: 0.4514\n",
      "Epoch 3 loss: 0.4921\n",
      "Epoch 3 loss: 0.4849\n",
      "Epoch 3 loss: 0.4495\n",
      "Epoch 3 loss: 0.4609\n",
      "Epoch 3 loss: 0.5055\n",
      "Epoch 3 loss: 0.4940\n",
      "Epoch 3 loss: 0.5229\n",
      "Epoch 3 loss: 0.4613\n",
      "Epoch 3 loss: 0.4273\n",
      "Epoch 3 loss: 0.4744\n",
      "Epoch 3 loss: 0.4565\n",
      "Epoch 3 loss: 0.4436\n",
      "Epoch 3 loss: 0.4259\n",
      "Epoch 3 loss: 0.4358\n",
      "Epoch 3 loss: 0.4949\n",
      "Epoch 3 loss: 0.4891\n",
      "Epoch 3 loss: 0.4333\n",
      "Epoch 3 loss: 0.5615\n",
      "Epoch 3 loss: 0.4482\n",
      "Epoch 3 loss: 0.4979\n",
      "Epoch 3 loss: 0.5119\n",
      "Epoch 3 loss: 0.5452\n",
      "Epoch 3 loss: 0.4935\n",
      "Epoch 3 loss: 0.4359\n",
      "Epoch 3 loss: 0.5273\n",
      "Epoch 3 loss: 0.4960\n",
      "Epoch 3 loss: 0.5447\n",
      "Epoch 3 loss: 0.4383\n",
      "Epoch 3 loss: 0.4554\n",
      "Epoch 3 loss: 0.5044\n",
      "Epoch 3 loss: 0.4227\n",
      "Epoch 3 loss: 0.4829\n",
      "Epoch 3 loss: 0.4710\n",
      "Epoch 3 loss: 0.4429\n",
      "Epoch 3 loss: 0.4956\n",
      "Epoch 3 loss: 0.4614\n",
      "Epoch 3 loss: 0.5190\n",
      "Epoch 3 loss: 0.4404\n",
      "Epoch 3 loss: 0.5032\n",
      "Epoch 3 loss: 0.4872\n",
      "Epoch 3 loss: 0.4940\n",
      "Epoch 3 loss: 0.5101\n",
      "Epoch 3 loss: 0.4022\n",
      "Epoch 3 loss: 0.3970\n",
      "Epoch 3 loss: 0.5007\n",
      "Epoch 3 loss: 0.4553\n",
      "Epoch 3 loss: 0.4093\n",
      "Epoch 3 loss: 0.4890\n",
      "Epoch 3 loss: 0.4802\n",
      "Epoch 3 loss: 0.5034\n",
      "Epoch 3 loss: 0.4752\n",
      "Epoch 3 loss: 0.4399\n",
      "Epoch 3 loss: 0.4863\n",
      "Epoch 3 loss: 0.4444\n",
      "Epoch 3 loss: 0.4497\n",
      "Epoch 3 loss: 0.5114\n",
      "Epoch 3 loss: 0.4611\n",
      "Epoch 3 loss: 0.4654\n",
      "Epoch 3 loss: 0.4846\n",
      "Epoch 3 loss: 0.4736\n",
      "Epoch 3 loss: 0.4970\n",
      "Epoch 3 loss: 0.4691\n",
      "Epoch 3 loss: 0.4427\n",
      "Epoch 3 loss: 0.5259\n",
      "Epoch 3 loss: 0.5102\n",
      "Epoch 3 loss: 0.3738\n",
      "Epoch 3 loss: 0.5132\n",
      "Epoch 3 loss: 0.4884\n",
      "Epoch 3 loss: 0.4244\n",
      "Epoch 3 loss: 0.4694\n",
      "Epoch 3 loss: 0.5157\n",
      "Epoch 3 loss: 0.5145\n",
      "Epoch 3 loss: 0.4964\n",
      "Epoch 3 loss: 0.4505\n",
      "Epoch 3 loss: 0.4580\n",
      "Epoch 3 loss: 0.4891\n",
      "Epoch 3 loss: 0.4893\n",
      "Epoch 3 loss: 0.5317\n",
      "Epoch 3 loss: 0.4955\n",
      "Epoch 3 loss: 0.4642\n",
      "Epoch 3 loss: 0.5285\n",
      "Epoch 3 loss: 0.4785\n",
      "Epoch 3 loss: 0.5230\n",
      "Epoch 3 loss: 0.4762\n",
      "Epoch 3 loss: 0.5056\n",
      "Epoch 3 loss: 0.4524\n",
      "Epoch 3 loss: 0.4401\n",
      "Epoch 3 loss: 0.4794\n",
      "Epoch 3 loss: 0.4642\n",
      "Epoch 3 loss: 0.5267\n",
      "Epoch 3 loss: 0.5011\n",
      "Epoch 3 loss: 0.5151\n",
      "Epoch 3 loss: 0.4886\n",
      "Epoch 3 loss: 0.4879\n",
      "Epoch 3 loss: 0.5027\n",
      "Epoch 3 loss: 0.4265\n",
      "Epoch 3 loss: 0.4476\n",
      "Epoch 3 loss: 0.5380\n",
      "Epoch 3 loss: 0.4278\n",
      "Epoch 3 loss: 0.4983\n",
      "Epoch 3 loss: 0.4475\n",
      "Epoch 3 loss: 0.4736\n",
      "Epoch 3 loss: 0.4583\n",
      "Epoch 3 loss: 0.4263\n",
      "Epoch 3 loss: 0.4631\n",
      "Epoch 3 loss: 0.5151\n",
      "Epoch 3 loss: 0.4996\n",
      "Epoch 3 loss: 0.4711\n",
      "Epoch 3 loss: 0.4307\n",
      "Epoch 3 loss: 0.5366\n",
      "Epoch 3 loss: 0.5234\n",
      "Epoch 3 loss: 0.4272\n",
      "Epoch 3 loss: 0.4577\n",
      "Epoch 3 loss: 0.4712\n",
      "Epoch 3 loss: 0.4957\n",
      "Epoch 3 loss: 0.4583\n",
      "Epoch 3 loss: 0.4634\n",
      "Epoch 3 loss: 0.4128\n",
      "Epoch 3 loss: 0.4614\n",
      "Epoch 3 loss: 0.4808\n",
      "Epoch 3 loss: 0.4048\n",
      "Epoch 3 loss: 0.4439\n",
      "Epoch 3 loss: 0.4806\n",
      "Epoch 3 loss: 0.5026\n",
      "Epoch 3 loss: 0.4470\n",
      "Epoch 3 loss: 0.5237\n",
      "Epoch 3 loss: 0.4758\n",
      "Epoch 3 loss: 0.5015\n",
      "Epoch 3 loss: 0.4487\n",
      "Epoch 3 loss: 0.4556\n",
      "Epoch 3 loss: 0.4715\n",
      "Epoch 3 loss: 0.4195\n",
      "Epoch 3 loss: 0.4980\n",
      "Epoch 3 loss: 0.4497\n",
      "Epoch 3 loss: 0.4671\n",
      "Epoch 3 loss: 0.4744\n",
      "Epoch 3 loss: 0.5290\n",
      "Epoch 3 loss: 0.4086\n",
      "Epoch 3 loss: 0.4106\n",
      "Epoch 3 loss: 0.4365\n",
      "Epoch 3 loss: 0.5075\n",
      "Epoch 3 loss: 0.4547\n",
      "Epoch 3 loss: 0.4517\n",
      "Epoch 3 loss: 0.4825\n",
      "Epoch 3 loss: 0.4855\n",
      "Epoch 3 loss: 0.4518\n",
      "Epoch 3 loss: 0.4561\n",
      "Epoch 3 loss: 0.4286\n",
      "Epoch 3 loss: 0.4410\n",
      "Epoch 3 loss: 0.4780\n",
      "Epoch 3 loss: 0.3709\n",
      "Epoch 3 loss: 0.4684\n",
      "Epoch 3 loss: 0.4175\n",
      "Epoch 3 loss: 0.4486\n",
      "Epoch 3 loss: 0.4500\n",
      "Epoch 3 loss: 0.4692\n",
      "Epoch 3 loss: 0.4571\n",
      "Epoch 3 loss: 0.4350\n",
      "Epoch 3 loss: 0.4963\n",
      "Epoch 3 loss: 0.4672\n",
      "Epoch 3 loss: 0.4798\n",
      "Epoch 3 loss: 0.4366\n",
      "Epoch 3 loss: 0.4984\n",
      "Epoch 3 loss: 0.4212\n",
      "Epoch 3 loss: 0.4881\n",
      "Epoch 3 loss: 0.4481\n",
      "Epoch 3 loss: 0.4763\n",
      "Epoch 3 loss: 0.4859\n",
      "Epoch 3 loss: 0.4255\n",
      "Epoch 3 loss: 0.4671\n",
      "Epoch 3 loss: 0.4469\n",
      "Epoch 3 loss: 0.4955\n",
      "Epoch 3 loss: 0.4222\n",
      "Epoch 3 loss: 0.4484\n",
      "Epoch 3 loss: 0.4381\n",
      "Epoch 3 loss: 0.5002\n",
      "Epoch 3 loss: 0.3951\n",
      "Epoch 3 loss: 0.5167\n",
      "Epoch 3 loss: 0.4620\n",
      "Epoch 3 loss: 0.4560\n",
      "Epoch 3 loss: 0.4551\n",
      "Epoch 3 loss: 0.4576\n",
      "Epoch 3 loss: 0.4214\n",
      "Epoch 3 loss: 0.4525\n",
      "Epoch 3 loss: 0.4563\n",
      "Epoch 3 loss: 0.4424\n",
      "Epoch 3 loss: 0.4232\n",
      "Epoch 3 loss: 0.4959\n",
      "Epoch 3 loss: 0.4561\n",
      "Epoch 3 loss: 0.4691\n",
      "Epoch 3 loss: 0.4637\n",
      "Epoch 3 loss: 0.4664\n",
      "Epoch 3 loss: 0.5103\n",
      "Epoch 3 loss: 0.4682\n",
      "Epoch 3 loss: 0.4328\n",
      "Epoch 3 loss: 0.4394\n",
      "Epoch 3 loss: 0.4168\n",
      "Epoch 3 loss: 0.4640\n",
      "Epoch 3 loss: 0.4255\n",
      "Epoch 3 loss: 0.4106\n",
      "Epoch 3 loss: 0.4206\n",
      "Epoch 3 loss: 0.5242\n",
      "Epoch 3 loss: 0.4331\n",
      "Epoch 3 loss: 0.4722\n",
      "Epoch 3 loss: 0.4349\n",
      "Epoch 3 loss: 0.5078\n",
      "Epoch 3 loss: 0.4375\n",
      "Epoch 3 loss: 0.5215\n",
      "Epoch 3 loss: 0.4271\n",
      "Epoch 3 loss: 0.5181\n",
      "Epoch 3 loss: 0.4085\n",
      "Epoch 3 loss: 0.4486\n",
      "Epoch 3 loss: 0.4837\n",
      "Epoch 3 loss: 0.3821\n",
      "Epoch 3 loss: 0.4021\n",
      "Epoch 3 loss: 0.4709\n",
      "Epoch 3 loss: 0.4681\n",
      "Epoch 3 loss: 0.4872\n",
      "Epoch 3 loss: 0.4829\n",
      "Epoch 3 loss: 0.4671\n",
      "Epoch 3 loss: 0.4636\n",
      "Epoch 3 loss: 0.4007\n",
      "Epoch 3 loss: 0.4624\n",
      "Epoch 3 loss: 0.4458\n",
      "Epoch 3 loss: 0.4190\n",
      "Epoch 3 loss: 0.4471\n",
      "Epoch 3 loss: 0.4878\n",
      "Epoch 3 loss: 0.4626\n",
      "Epoch 3 loss: 0.5261\n",
      "Epoch 3 loss: 0.4821\n",
      "Epoch 3 loss: 0.4540\n",
      "Epoch 3 loss: 0.4366\n",
      "Epoch 3 loss: 0.4338\n",
      "Epoch 3 loss: 0.4421\n",
      "Epoch 3 loss: 0.4455\n",
      "Epoch 3 loss: 0.4455\n",
      "Epoch 3 loss: 0.4383\n",
      "Epoch 3 loss: 0.4202\n",
      "Epoch 3 loss: 0.4834\n",
      "Epoch 3 loss: 0.4644\n",
      "Epoch 3 loss: 0.4577\n",
      "Epoch 3 loss: 0.4398\n",
      "Epoch 3 loss: 0.5129\n",
      "Epoch 3 loss: 0.4712\n",
      "Epoch 3 loss: 0.4914\n",
      "Epoch 3 loss: 0.5163\n",
      "Epoch 3 loss: 0.4412\n",
      "Epoch 3 loss: 0.3892\n",
      "Epoch 3 loss: 0.4711\n",
      "Epoch 3 loss: 0.3862\n",
      "Epoch 3 loss: 0.4466\n",
      "Epoch 3 loss: 0.4064\n",
      "Epoch 3 loss: 0.4480\n",
      "Epoch 3 loss: 0.4451\n",
      "Epoch 3 loss: 0.4628\n",
      "Epoch 3 loss: 0.4853\n",
      "Epoch 3 loss: 0.4616\n",
      "Epoch 3 loss: 0.4954\n",
      "Epoch 3 loss: 0.4750\n",
      "Epoch 3 loss: 0.5087\n",
      "Epoch 3 loss: 0.4088\n",
      "Epoch 3 loss: 0.4201\n",
      "Epoch 3 loss: 0.4350\n",
      "Epoch 3 loss: 0.4754\n",
      "Epoch 3 loss: 0.4485\n",
      "Epoch 3 loss: 0.5691\n",
      "Epoch 3 loss: 0.3708\n",
      "Epoch 3 loss: 0.4291\n",
      "Epoch 3 loss: 0.4738\n",
      "Epoch 3 loss: 0.4334\n",
      "Epoch 3 loss: 0.3975\n",
      "Epoch 3 loss: 0.4766\n",
      "Epoch 3 loss: 0.4555\n",
      "Epoch 3 loss: 0.4451\n",
      "Epoch 3 loss: 0.4440\n",
      "Epoch 3 loss: 0.4619\n",
      "Epoch 3 loss: 0.5063\n",
      "Epoch 3 loss: 0.3930\n",
      "Epoch 3 loss: 0.3540\n",
      "Epoch 3 loss: 0.5161\n",
      "Epoch 3 loss: 0.4334\n",
      "Epoch 3 loss: 0.4414\n",
      "Epoch 3 loss: 0.4502\n",
      "Epoch 3 loss: 0.4585\n",
      "Epoch 3 loss: 0.5050\n",
      "Epoch 3 loss: 0.4502\n",
      "Epoch 3 loss: 0.3943\n",
      "Epoch 3 loss: 0.3921\n",
      "Epoch 3 loss: 0.3860\n",
      "Epoch 3 loss: 0.4339\n",
      "Epoch 3 loss: 0.5192\n",
      "Epoch 3 loss: 0.4823\n",
      "Epoch 3 loss: 0.5052\n",
      "Epoch 3 loss: 0.3805\n",
      "Epoch 3 loss: 0.4626\n",
      "Epoch 3 loss: 0.4347\n",
      "Epoch 3 loss: 0.4628\n",
      "Epoch 3 loss: 0.4551\n",
      "Epoch 3 loss: 0.4233\n",
      "Epoch 3 loss: 0.4654\n",
      "Epoch 3 loss: 0.4808\n",
      "Epoch 3 loss: 0.3953\n",
      "Epoch 3 loss: 0.3872\n",
      "Epoch 3 loss: 0.4238\n",
      "Epoch 3 loss: 0.4953\n",
      "Epoch 3 loss: 0.5554\n",
      "Epoch 3 loss: 0.4693\n",
      "Epoch 3 loss: 0.4505\n",
      "Epoch 3 loss: 0.4308\n",
      "Epoch 3 loss: 0.5401\n",
      "Epoch 3 loss: 0.4555\n",
      "Epoch 3 loss: 0.4441\n",
      "Epoch 3 loss: 0.4714\n",
      "Epoch 3 loss: 0.4832\n",
      "Epoch 3 loss: 0.4644\n",
      "Epoch 3 loss: 0.4349\n",
      "Epoch 3 loss: 0.4660\n",
      "Epoch 3 loss: 0.4998\n",
      "Epoch 3 loss: 0.4760\n",
      "Epoch 3 loss: 0.4596\n",
      "Epoch 3 loss: 0.4903\n",
      "Epoch 3 loss: 0.4325\n",
      "Epoch 3 loss: 0.4632\n",
      "Epoch 3 loss: 0.4115\n",
      "Epoch 3 loss: 0.4698\n",
      "Epoch 3 loss: 0.4564\n",
      "Epoch 3 loss: 0.4619\n",
      "Epoch 3 loss: 0.3976\n",
      "Epoch 3 loss: 0.4255\n",
      "Epoch 3 loss: 0.4762\n",
      "Epoch 3 loss: 0.4709\n",
      "Epoch 3 loss: 0.4707\n",
      "Epoch 3 loss: 0.5186\n",
      "Epoch 3 loss: 0.4917\n",
      "Epoch 3 loss: 0.4318\n",
      "Epoch 3 loss: 0.4470\n",
      "Epoch 3 loss: 0.4089\n",
      "Epoch 3 loss: 0.4764\n",
      "Epoch 3 loss: 0.4271\n",
      "Epoch 3 loss: 0.4459\n",
      "Epoch 3 loss: 0.4488\n",
      "Epoch 3 loss: 0.4422\n",
      "Epoch 3 loss: 0.4498\n",
      "Epoch 3 loss: 0.4668\n",
      "Epoch 3 loss: 0.4179\n",
      "Epoch 3 loss: 0.4622\n",
      "Epoch 3 loss: 0.4600\n",
      "Epoch 3 loss: 0.4580\n",
      "Epoch 3 loss: 0.4324\n",
      "Epoch 3 loss: 0.4963\n",
      "Epoch 3 loss: 0.4507\n",
      "Epoch 3 loss: 0.3925\n",
      "Epoch 3 loss: 0.4163\n",
      "Epoch 3 loss: 0.4520\n",
      "Epoch 3 loss: 0.5136\n",
      "Epoch 3 loss: 0.4217\n",
      "Epoch 3 loss: 0.4368\n",
      "Epoch 3 loss: 0.4761\n",
      "Epoch 3 loss: 0.4735\n",
      "Epoch 3 loss: 0.5298\n",
      "Epoch 3 loss: 0.4184\n",
      "Epoch 3 loss: 0.4540\n",
      "Epoch 3 loss: 0.4166\n",
      "Epoch 3 loss: 0.4526\n",
      "Epoch 3 loss: 0.4053\n",
      "Epoch 3 loss: 0.3993\n",
      "Epoch 3 loss: 0.4481\n",
      "Epoch 3 loss: 0.4141\n",
      "Epoch 3 loss: 0.4500\n",
      "Epoch 3 loss: 0.4323\n",
      "Epoch 3 loss: 0.4407\n",
      "Epoch 3 loss: 0.4529\n",
      "Epoch 3 loss: 0.4350\n",
      "Epoch 3 loss: 0.4928\n",
      "Epoch 3 loss: 0.4231\n",
      "Epoch 3 loss: 0.3798\n",
      "Epoch 3 loss: 0.4543\n",
      "Epoch 3 loss: 0.4506\n",
      "Epoch 3 loss: 0.4518\n",
      "Epoch 3 loss: 0.4158\n",
      "Epoch 3 loss: 0.4238\n",
      "Epoch 3 loss: 0.4307\n",
      "Epoch 3 loss: 0.4174\n",
      "Epoch 3 loss: 0.4845\n",
      "Epoch 3 loss: 0.3506\n",
      "Epoch 3 loss: 0.3945\n",
      "Epoch 3 loss: 0.5214\n",
      "Epoch 3 loss: 0.4884\n",
      "Epoch 3 loss: 0.4430\n",
      "Epoch 3 loss: 0.4357\n",
      "Epoch 3 loss: 0.4285\n",
      "Epoch 3 loss: 0.4354\n",
      "Epoch 3 loss: 0.4445\n",
      "Epoch 3 loss: 0.4445\n",
      "Epoch 3 loss: 0.4572\n",
      "Epoch 3 loss: 0.5103\n",
      "Epoch 3 loss: 0.4089\n",
      "Epoch 3 loss: 0.4381\n",
      "Epoch 3 loss: 0.4041\n",
      "Epoch 3 loss: 0.4583\n",
      "Epoch 3 loss: 0.4461\n",
      "Epoch 3 loss: 0.4310\n",
      "Epoch 3 loss: 0.4562\n",
      "Epoch 3 loss: 0.4612\n",
      "Epoch 3 loss: 0.4395\n",
      "Epoch 3 loss: 0.4022\n",
      "Epoch 3 loss: 0.5418\n",
      "Epoch 3 loss: 0.4254\n",
      "Epoch 3 loss: 0.4947\n",
      "Epoch 3 loss: 0.4758\n",
      "Epoch 3 loss: 0.3704\n",
      "Epoch 3 loss: 0.4536\n",
      "Epoch 3 loss: 0.4341\n",
      "Epoch 3 loss: 0.4659\n",
      "Epoch 3 loss: 0.4422\n",
      "Epoch 3 loss: 0.4764\n",
      "Epoch 3 loss: 0.4468\n",
      "Epoch 3 loss: 0.3460\n",
      "Epoch 3 loss: 0.3906\n",
      "Epoch 3 loss: 0.4012\n",
      "Epoch 3 loss: 0.4644\n",
      "Epoch 3 loss: 0.4104\n",
      "Epoch 3 loss: 0.4192\n",
      "Epoch 3 loss: 0.4615\n",
      "Epoch 3 loss: 0.4338\n",
      "Epoch 3 loss: 0.4401\n",
      "Epoch 3 loss: 0.4362\n",
      "Epoch 3 loss: 0.4960\n",
      "Epoch 3 loss: 0.5206\n",
      "Epoch 3 loss: 0.4482\n",
      "Epoch 3 loss: 0.4188\n",
      "Epoch 3 loss: 0.3937\n",
      "Epoch 3 loss: 0.3994\n",
      "Epoch 3 loss: 0.4123\n",
      "Epoch 3 loss: 0.4591\n",
      "Epoch 3 loss: 0.3961\n",
      "Epoch 3 loss: 0.4665\n",
      "Epoch 3 loss: 0.4743\n",
      "Epoch 3 loss: 0.3964\n",
      "Epoch 3 loss: 0.3889\n",
      "Epoch 3 loss: 0.4050\n",
      "Epoch 3 loss: 0.4002\n",
      "Epoch 3 loss: 0.4640\n",
      "Epoch 3 loss: 0.4651\n",
      "Epoch 3 loss: 0.4534\n",
      "Epoch 3 loss: 0.4953\n",
      "Epoch 3 loss: 0.3756\n",
      "Epoch 3 loss: 0.4509\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "train_dl = DataLoader(\n",
    "    tokenized_ds[\"train\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=DataCollatorWithPadding(tokenizer),\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Optimizer & device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_dl:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Epoch {epoch+1} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa404fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
